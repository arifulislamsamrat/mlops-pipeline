name: Deploy MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: ap-southeast-1
  PULUMI_STACK: dev

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [ml-inference, data-ingestion]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies and run tests
      run: |
        cd services/${{ matrix.service }}
        pip install -r requirements.txt
        pip install pytest
        
        # Check if tests directory exists
        if [ -d "tests" ]; then
          echo "Tests directory found, running pytest..."
          python -m pytest tests/ -v --tb=short
        else
          echo "Tests directory not found, running basic health test..."
          python -c "
        import sys
        sys.path.insert(0, '.')
        try:
            from app import app
            print('✓ App import successful')
            client = app.test_client()
            response = client.get('/health')
            print(f'✓ Health check: {response.status_code}')
            assert response.status_code == 200
            print('✓ Basic health test passed')
        except Exception as e:
            print(f'✗ Test failed: {e}')
            sys.exit(1)
          "
        fi

  deploy-infrastructure:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    outputs:
      instance_ip: ${{ steps.get-outputs.outputs.instance_ip }}
      ml_inference_repo: ${{ steps.get-outputs.outputs.ml_inference_repo }}
      data_ingestion_repo: ${{ steps.get-outputs.outputs.data_ingestion_repo }}

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Download Pulumi state
      uses: actions/download-artifact@v4
      with:
        name: pulumi-state
        path: ~/.pulumi

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Pulumi
      run: |
        curl -fsSL https://get.pulumi.com | sh
        echo "$HOME/.pulumi/bin" >> $GITHUB_PATH

    - name: Deploy infrastructure
      env:
        PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
      run: |
        cd infrastructure
        pip install -r requirements.txt
        pulumi login --local
        pulumi stack select ${{ env.PULUMI_STACK }} --create
        pulumi up --yes

    - name: Get deployment outputs
      id: get-outputs
      env:
        PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
      run: |
        cd infrastructure
        echo "instance_ip=$(pulumi stack output instance_public_ip)" >> $GITHUB_OUTPUT
        echo "ml_inference_repo=$(pulumi stack output ml_inference_repo_url)" >> $GITHUB_OUTPUT
        echo "data_ingestion_repo=$(pulumi stack output data_ingestion_repo_url)" >> $GITHUB_OUTPUT

    - name: Upload Pulumi state
      uses: actions/upload-artifact@v4
      with:
        name: pulumi-state
        path: ~/.pulumi
        retention-days: 1

  build-and-push:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix:
        service: [ml-inference, data-ingestion]

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Download Pulumi state
      uses: actions/download-artifact@v4
      with:
        name: pulumi-state
        path: ~/.pulumi

    - name: Download Pulumi state
      uses: actions/download-artifact@v4
      with:
        name: pulumi-state
        path: ~/.pulumi

    - name: Get Pulumi outputs
      id: pulumi-outputs
      env:
        PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
      run: |
        cd infrastructure
        pip install pulumi pulumi-aws
        pulumi login --local
        
        if [ "${{ matrix.service }}" == "ml-inference" ]; then
          echo "repository_url=${{ needs.deploy-infrastructure.outputs.ml_inference_repo }}" >> $GITHUB_OUTPUT
        else
          echo "repository_url=${{ needs.deploy-infrastructure.outputs.data_ingestion_repo }}" >> $GITHUB_OUTPUT
        fi

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REPOSITORY: ${{ steps.pulumi-outputs.outputs.repository_url }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cd services/${{ matrix.service }}
        
        # Debug: List files to ensure we're in the right place
        echo "Current directory contents:"
        ls -la
        
        # Build the Docker image
        docker build -t $ECR_REPOSITORY:$IMAGE_TAG .
        docker tag $ECR_REPOSITORY:$IMAGE_TAG $ECR_REPOSITORY:latest
        
        # Push images
        docker push $ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REPOSITORY:latest
        
        echo "Successfully built and pushed ${{ matrix.service }}"

  deploy-services:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Download Pulumi state
      uses: actions/download-artifact@v4
      with:
        name: pulumi-state
        path: ~/.pulumi

    - name: Get instance details
      id: get-instance
      env:
        PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
      run: |
        cd infrastructure
        pip install pulumi pulumi-aws
        pulumi login --local
        echo "instance_ip=${{ needs.deploy-infrastructure.outputs.instance_ip }}" >> $GITHUB_OUTPUT

    - name: Deploy services to EC2
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ steps.get-instance.outputs.instance_ip }}
        username: ubuntu
        key: ${{ secrets.EC2_SSH_KEY }}
        timeout: 300s
        script: |
          # Wait for Docker to be ready
          echo "Waiting for Docker to be ready..."
          timeout=60
          while ! docker info > /dev/null 2>&1; do
            echo "Waiting for Docker to start..."
            sleep 5
            timeout=$((timeout-5))
            if [ $timeout -le 0 ]; then
              echo "Docker failed to start within timeout"
              exit 1
            fi
          done
          echo "Docker is ready!"

          # Configure AWS CLI region
          aws configure set default.region ap-southeast-1

          # Login to ECR
          echo "Logging into ECR..."
          aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.ap-southeast-1.amazonaws.com

          # Create monitoring directories
          echo "Setting up monitoring directories..."
          mkdir -p /home/ubuntu/monitoring/prometheus
          mkdir -p /home/ubuntu/monitoring/grafana/provisioning/datasources
          mkdir -p /home/ubuntu/monitoring/grafana/provisioning/dashboards
          mkdir -p /home/ubuntu/monitoring/grafana/dashboards

          # Create Prometheus config
          cat > /home/ubuntu/monitoring/prometheus/prometheus.yml << 'PROMETHEUS_EOF'
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          scrape_configs:
            - job_name: 'ml-inference'
              static_configs:
                - targets: ['ml-inference:8001']
              metrics_path: '/metrics'
            - job_name: 'data-ingestion'
              static_configs:
                - targets: ['data-ingestion:8002']
              metrics_path: '/metrics'
          PROMETHEUS_EOF

          # Create Grafana datasource config
          cat > /home/ubuntu/monitoring/grafana/provisioning/datasources/prometheus.yml << 'DATASOURCE_EOF'
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://prometheus:9090
              isDefault: true
              editable: false
          DATASOURCE_EOF

          # Create Grafana dashboard provisioning config
          cat > /home/ubuntu/monitoring/grafana/provisioning/dashboards/dashboard.yml << 'DASHBOARD_EOF'
          apiVersion: 1
          providers:
            - name: 'MLOps Dashboards'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              updateIntervalSeconds: 10
              allowUiUpdates: true
              options:
                path: /var/lib/grafana/dashboards
                foldersFromFilesStructure: true
          DASHBOARD_EOF

          # Get ECR repository URLs
          echo "Getting ECR repository URLs..."
          ML_INFERENCE_REPO=$(aws ecr describe-repositories --repository-names mlops/ml-inference --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
          DATA_INGESTION_REPO=$(aws ecr describe-repositories --repository-names mlops/data-ingestion --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")

          if [ -z "$ML_INFERENCE_REPO" ] || [ -z "$DATA_INGESTION_REPO" ]; then
            echo "Error: Could not retrieve ECR repository URLs"
            echo "ML_INFERENCE_REPO: $ML_INFERENCE_REPO"
            echo "DATA_INGESTION_REPO: $DATA_INGESTION_REPO"
            exit 1
          fi

          echo "Repository URLs retrieved:"
          echo "ML Inference: $ML_INFERENCE_REPO"
          echo "Data Ingestion: $DATA_INGESTION_REPO"

          # Create docker-compose.yml
          cat > /home/ubuntu/docker-compose.yml << COMPOSE_EOF
          version: '3.8'
          services:
            ml-inference:
              image: ${ML_INFERENCE_REPO}:latest
              ports:
                - "8001:8001"
              restart: always
              networks:
                - mlops-network
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                
            data-ingestion:
              image: ${DATA_INGESTION_REPO}:latest
              ports:
                - "8002:8002"
              restart: always
              networks:
                - mlops-network
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                
            prometheus:
              image: prom/prometheus:latest
              ports:
                - "9090:9090"
              volumes:
                - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
                - prometheus-data:/prometheus
              command:
                - '--config.file=/etc/prometheus/prometheus.yml'
                - '--storage.tsdb.path=/prometheus'
              restart: always
              networks:
                - mlops-network
                
            grafana:
              image: grafana/grafana:latest
              ports:
                - "3000:3000"
              environment:
                - GF_SECURITY_ADMIN_PASSWORD=admin
                - GF_USERS_ALLOW_SIGN_UP=false
              volumes:
                - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
                - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
                - grafana-data:/var/lib/grafana
              depends_on:
                - prometheus
              restart: always
              networks:
                - mlops-network
                
          networks:
            mlops-network:
              driver: bridge
              
          volumes:
            prometheus-data:
            grafana-data:
          COMPOSE_EOF

          # Pull latest images
          echo "Pulling latest images..."
          docker pull ${ML_INFERENCE_REPO}:latest || exit 1
          docker pull ${DATA_INGESTION_REPO}:latest || exit 1

          # Deploy services
          echo "Deploying services..."
          cd /home/ubuntu
          docker-compose down || true
          docker-compose up -d

          # Wait for services to start
          echo "Waiting for services to start..."
          sleep 60

          # Check service health with retries
          echo "Checking service health..."
          for i in {1..5}; do
            if curl -f http://localhost:8001/health && curl -f http://localhost:8002/health; then
              echo "✓ All services are healthy!"
              exit 0
            else
              echo "Attempt $i: Services not ready yet, waiting..."
              sleep 30
            fi
          done
          
          echo "✗ Services failed to become healthy"
          docker-compose logs
          exit 1
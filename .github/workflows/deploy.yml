name: Deploy MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: ap-southeast-1
  PULUMI_STACK: rfsamrat/mlops-pipeline/dev

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [ml-inference, data-ingestion]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies and run tests
      run: |
        cd services/${{ matrix.service }}
        pip install -r requirements.txt
        pip install pytest
        
        # Check if tests directory exists
        if [ -d "tests" ]; then
          echo "Tests directory found, running pytest..."
          python -m pytest tests/ -v --tb=short
        else
          echo "Tests directory not found, running basic health test..."
          python -c "
        import sys
        sys.path.insert(0, '.')
        try:
            from app import app
            print('✓ App import successful')
            client = app.test_client()
            response = client.get('/health')
            print(f'✓ Health check: {response.status_code}')
            assert response.status_code == 200
            print('✓ Basic health test passed')
        except Exception as e:
            print(f'✗ Test failed: {e}')
            sys.exit(1)
          "
        fi

  deploy-infrastructure:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    outputs:
      instance_ip: ${{ steps.get-outputs.outputs.instance_ip }}
      ml_inference_repo: ${{ steps.get-outputs.outputs.ml_inference_repo }}
      data_ingestion_repo: ${{ steps.get-outputs.outputs.data_ingestion_repo }}
      unique_suffix: ${{ steps.get-outputs.outputs.unique_suffix }}

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Pulumi
      run: |
        curl -fsSL https://get.pulumi.com | sh
        echo "$HOME/.pulumi/bin" >> $GITHUB_PATH

    - name: Clean up existing ECR repositories
      run: |
        echo "Cleaning up existing ECR repositories..."
        
        # Clean up any MLOps ECR repositories
        REPOS=$(aws ecr describe-repositories --query 'repositories[?contains(repositoryName, `mlops/`)].repositoryName' --output text 2>/dev/null || echo "")
        
        if [ ! -z "$REPOS" ]; then
          for repo in $REPOS; do
            echo "Force deleting repository: $repo"
            aws ecr delete-repository --repository-name "$repo" --force || true
          done
          echo "ECR cleanup completed"
        else
          echo "No existing MLOps ECR repositories found"
        fi

    - name: Deploy infrastructure
      env:
        PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
      run: |
        cd infrastructure
        pip install -r requirements.txt
        pulumi login
        pulumi stack select ${{ env.PULUMI_STACK }} --create
        pulumi up --yes

    - name: Get deployment outputs
      id: get-outputs
      env:
        PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
      run: |
        cd infrastructure
        echo "instance_ip=$(pulumi stack output instance_public_ip)" >> $GITHUB_OUTPUT
        echo "ml_inference_repo=$(pulumi stack output ml_inference_repo_url)" >> $GITHUB_OUTPUT
        echo "data_ingestion_repo=$(pulumi stack output data_ingestion_repo_url)" >> $GITHUB_OUTPUT
        echo "unique_suffix=$(pulumi stack output unique_suffix)" >> $GITHUB_OUTPUT

  build-and-push:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix:
        service: [ml-inference, data-ingestion]

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Get Pulumi outputs
      id: pulumi-outputs
      run: |
        if [ "${{ matrix.service }}" == "ml-inference" ]; then
          echo "repository_url=${{ needs.deploy-infrastructure.outputs.ml_inference_repo }}" >> $GITHUB_OUTPUT
        else
          echo "repository_url=${{ needs.deploy-infrastructure.outputs.data_ingestion_repo }}" >> $GITHUB_OUTPUT
        fi

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REPOSITORY: ${{ steps.pulumi-outputs.outputs.repository_url }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cd services/${{ matrix.service }}
        
        # Debug: List files to ensure we're in the right place
        echo "Current directory contents:"
        ls -la
        
        # Build the Docker image
        docker build -t $ECR_REPOSITORY:$IMAGE_TAG .
        docker tag $ECR_REPOSITORY:$IMAGE_TAG $ECR_REPOSITORY:latest
        
        # Push images
        docker push $ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REPOSITORY:latest
        
        echo "Successfully built and pushed ${{ matrix.service }}"

  deploy-services:
    needs: [deploy-infrastructure, build-and-push]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get instance details
      id: get-instance
      run: |
        echo "instance_ip=${{ needs.deploy-infrastructure.outputs.instance_ip }}" >> $GITHUB_OUTPUT
        echo "unique_suffix=${{ needs.deploy-infrastructure.outputs.unique_suffix }}" >> $GITHUB_OUTPUT

    - name: Deploy services to EC2
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ steps.get-instance.outputs.instance_ip }}
        username: ubuntu
        key: ${{ secrets.EC2_SSH_KEY }}
        timeout: 900s
        script: |
          # Wait for cloud-init to complete first
          echo "Waiting for cloud-init to complete..."
          sudo cloud-init status --wait || true
          
          # Wait for user_data script to complete
          echo "Waiting for user_data script to complete..."
          timeout=300
          while [ ! -f /home/ubuntu/setup-info.txt ]; do
            echo "Waiting for EC2 initialization to complete..."
            sleep 10
            timeout=$((timeout-10))
            if [ $timeout -le 0 ]; then
              echo "EC2 initialization timeout - proceeding anyway..."
              break
            fi
          done
          
          # Wait for Docker to be ready
          echo "Waiting for Docker to be ready..."
          timeout=300
          while ! sudo docker info > /dev/null 2>&1; do
            echo "Waiting for Docker to start..."
            
            # Try to start Docker if it's not running
            sudo systemctl start docker || true
            sudo systemctl enable docker || true
            
            sleep 15
            timeout=$((timeout-15))
            if [ $timeout -le 0 ]; then
              echo "Docker failed to start within timeout"
              echo "Checking Docker status..."
              sudo systemctl status docker || true
              echo "Trying to install Docker manually..."
              curl -fsSL https://get.docker.com -o get-docker.sh
              sudo sh get-docker.sh
              sudo usermod -aG docker ubuntu
              sudo systemctl start docker
              sleep 30
              break
            fi
          done
          
          # Verify Docker is working
          if sudo docker info > /dev/null 2>&1; then
            echo "Docker is ready!"
          else
            echo "Docker is still not ready, but continuing..."
          fi

          # Configure AWS CLI region
          aws configure set default.region ap-southeast-1

          # Login to ECR
          echo "Logging into ECR..."
          aws ecr get-login-password --region ap-southeast-1 | sudo docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.ap-southeast-1.amazonaws.com

          # Create monitoring directories
          echo "Setting up monitoring directories..."
          mkdir -p /home/ubuntu/monitoring/prometheus
          mkdir -p /home/ubuntu/monitoring/grafana/provisioning/datasources
          mkdir -p /home/ubuntu/monitoring/grafana/provisioning/dashboards
          mkdir -p /home/ubuntu/monitoring/grafana/dashboards

          # Create Prometheus config
          cat > /home/ubuntu/monitoring/prometheus/prometheus.yml << 'PROMETHEUS_EOF'
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          scrape_configs:
            - job_name: 'ml-inference'
              static_configs:
                - targets: ['ml-inference:8001']
              metrics_path: '/metrics'
              scrape_interval: 30s
            - job_name: 'data-ingestion'
              static_configs:
                - targets: ['data-ingestion:8002']
              metrics_path: '/metrics'
              scrape_interval: 30s
          PROMETHEUS_EOF

          # Create Grafana datasource config
          cat > /home/ubuntu/monitoring/grafana/provisioning/datasources/prometheus.yml << 'DATASOURCE_EOF'
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://prometheus:9090
              isDefault: true
              editable: false
          DATASOURCE_EOF

          # Create Grafana dashboard provisioning config
          cat > /home/ubuntu/monitoring/grafana/provisioning/dashboards/dashboard.yml << 'DASHBOARD_EOF'
          apiVersion: 1
          providers:
            - name: 'MLOps Dashboards'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              updateIntervalSeconds: 10
              allowUiUpdates: true
              options:
                path: /var/lib/grafana/dashboards
                foldersFromFilesStructure: true
          DASHBOARD_EOF

          # Get ECR repository URLs with unique suffix
          UNIQUE_SUFFIX="${{ steps.get-instance.outputs.unique_suffix }}"
          echo "Using unique suffix: $UNIQUE_SUFFIX"
          
          ML_INFERENCE_REPO=$(aws ecr describe-repositories --repository-names "mlops/ml-inference-$UNIQUE_SUFFIX" --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
          DATA_INGESTION_REPO=$(aws ecr describe-repositories --repository-names "mlops/data-ingestion-$UNIQUE_SUFFIX" --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")

          if [ -z "$ML_INFERENCE_REPO" ] || [ -z "$DATA_INGESTION_REPO" ]; then
            echo "Error: Could not retrieve ECR repository URLs"
            echo "ML_INFERENCE_REPO: $ML_INFERENCE_REPO"
            echo "DATA_INGESTION_REPO: $DATA_INGESTION_REPO"
            
            # List available repositories
            echo "Available repositories:"
            aws ecr describe-repositories --query 'repositories[].repositoryName' --output text
            exit 1
          fi

          echo "Repository URLs retrieved:"
          echo "ML Inference: $ML_INFERENCE_REPO"
          echo "Data Ingestion: $DATA_INGESTION_REPO"

          # Create docker-compose.yml
          cat > /home/ubuntu/docker-compose.yml << COMPOSE_EOF
          version: '3.8'
          services:
            ml-inference:
              image: ${ML_INFERENCE_REPO}:latest
              ports:
                - "8001:8001"
              restart: always
              networks:
                - mlops-network
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
                
            data-ingestion:
              image: ${DATA_INGESTION_REPO}:latest
              ports:
                - "8002:8002"
              restart: always
              networks:
                - mlops-network
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
                
            prometheus:
              image: prom/prometheus:latest
              ports:
                - "9090:9090"
              volumes:
                - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
                - prometheus-data:/prometheus
              command:
                - '--config.file=/etc/prometheus/prometheus.yml'
                - '--storage.tsdb.path=/prometheus'
                - '--web.console.libraries=/etc/prometheus/console_libraries'
                - '--web.console.templates=/etc/prometheus/consoles'
                - '--storage.tsdb.retention.time=200h'
                - '--web.enable-lifecycle'
              restart: always
              networks:
                - mlops-network
                
            grafana:
              image: grafana/grafana:latest
              ports:
                - "3000:3000"
              environment:
                - GF_SECURITY_ADMIN_PASSWORD=admin
                - GF_USERS_ALLOW_SIGN_UP=false
                - GF_INSTALL_PLUGINS=
              volumes:
                - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
                - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
                - grafana-data:/var/lib/grafana
              depends_on:
                - prometheus
              restart: always
              networks:
                - mlops-network
                
          networks:
            mlops-network:
              driver: bridge
              
          volumes:
            prometheus-data:
            grafana-data:
          COMPOSE_EOF

          # Add user to docker group and ensure permissions
          sudo usermod -aG docker ubuntu
          newgrp docker || true

          # Pull latest images
          echo "Pulling latest images..."
          sudo docker pull ${ML_INFERENCE_REPO}:latest || exit 1
          sudo docker pull ${DATA_INGESTION_REPO}:latest || exit 1

          # Deploy services
          echo "Deploying services..."
          cd /home/ubuntu
          sudo docker-compose down || true
          sudo docker-compose up -d

          # Wait for services to start
          echo "Waiting for services to start..."
          sleep 120

          # Check service health with retries
          echo "Checking service health..."
          for i in {1..15}; do
            echo "Health check attempt $i..."
            
            ML_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8001/health 2>/dev/null || echo "000")
            DATA_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8002/health 2>/dev/null || echo "000")
            
            echo "ML Inference health: $ML_HEALTH"
            echo "Data Ingestion health: $DATA_HEALTH"
            
            if [ "$ML_HEALTH" = "200" ] && [ "$DATA_HEALTH" = "200" ]; then
              echo "✓ All services are healthy!"
              echo "🎉 Deployment completed successfully!"
              echo ""
              echo "Access URLs:"
              PUBLIC_IP=$(curl -s ifconfig.me)
              echo "- ML Inference: http://${PUBLIC_IP}:8001"
              echo "- Data Ingestion: http://${PUBLIC_IP}:8002"
              echo "- Prometheus: http://${PUBLIC_IP}:9090"
              echo "- Grafana: http://${PUBLIC_IP}:3000 (admin/admin)"
              exit 0
            else
              echo "Services not ready yet, waiting..."
              sleep 30
            fi
          done
          
          echo "✗ Services failed to become healthy within timeout"
          echo "Container logs:"
          sudo docker-compose logs --tail=50
          exit 1
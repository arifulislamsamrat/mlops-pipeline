name: Deploy MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: ap-southeast-1
  PULUMI_STACK: rfsamrat/mlops-pipeline/dev

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [ml-inference, data-ingestion]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies and run tests
      run: |
        cd services/${{ matrix.service }}
        pip install -r requirements.txt
        pip install pytest
        
        # Check if tests directory exists
        if [ -d "tests" ]; then
          echo "Tests directory found, running pytest..."
          python -m pytest tests/ -v --tb=short
        else
          echo "Tests directory not found, running basic health test..."
          python -c "
        import sys
        sys.path.insert(0, '.')
        try:
            from app import app
            print('âœ“ App import successful')
            client = app.test_client()
            response = client.get('/health')
            print(f'âœ“ Health check: {response.status_code}')
            assert response.status_code == 200
            print('âœ“ Basic health test passed')
        except Exception as e:
            print(f'âœ— Test failed: {e}')
            sys.exit(1)
          "
        fi

  deploy-infrastructure:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    outputs:
      instance_ip: ${{ steps.get-outputs.outputs.instance_ip }}
      ml_inference_repo: ${{ steps.get-outputs.outputs.ml_inference_repo }}
      data_ingestion_repo: ${{ steps.get-outputs.outputs.data_ingestion_repo }}
      unique_suffix: ${{ steps.get-outputs.outputs.unique_suffix }}

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Pulumi
      run: |
        curl -fsSL https://get.pulumi.com | sh
        echo "$HOME/.pulumi/bin" >> $GITHUB_PATH

    - name: Clean up existing ECR repositories
      run: |
        echo "Cleaning up existing ECR repositories..."
        
        # Clean up any MLOps ECR repositories
        REPOS=$(aws ecr describe-repositories --query 'repositories[?contains(repositoryName, `mlops/`)].repositoryName' --output text 2>/dev/null || echo "")
        
        if [ ! -z "$REPOS" ]; then
          for repo in $REPOS; do
            echo "Force deleting repository: $repo"
            aws ecr delete-repository --repository-name "$repo" --force || true
          done
          echo "ECR cleanup completed"
        else
          echo "No existing MLOps ECR repositories found"
        fi

    - name: Deploy infrastructure
      env:
        PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
      run: |
        cd infrastructure
        pip install -r requirements.txt
        pulumi login
        pulumi stack select ${{ env.PULUMI_STACK }} --create
        pulumi up --yes

    - name: Get deployment outputs
      id: get-outputs
      env:
        PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
      run: |
        cd infrastructure
        echo "instance_ip=$(pulumi stack output instance_public_ip)" >> $GITHUB_OUTPUT
        echo "ml_inference_repo=$(pulumi stack output ml_inference_repo_url)" >> $GITHUB_OUTPUT
        echo "data_ingestion_repo=$(pulumi stack output data_ingestion_repo_url)" >> $GITHUB_OUTPUT
        echo "unique_suffix=$(pulumi stack output unique_suffix)" >> $GITHUB_OUTPUT

  build-and-push:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix:
        service: [ml-inference, data-ingestion]

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Get Pulumi outputs
      id: pulumi-outputs
      run: |
        if [ "${{ matrix.service }}" == "ml-inference" ]; then
          echo "repository_url=${{ needs.deploy-infrastructure.outputs.ml_inference_repo }}" >> $GITHUB_OUTPUT
        else
          echo "repository_url=${{ needs.deploy-infrastructure.outputs.data_ingestion_repo }}" >> $GITHUB_OUTPUT
        fi

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REPOSITORY: ${{ steps.pulumi-outputs.outputs.repository_url }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cd services/${{ matrix.service }}
        
        # Debug: List files to ensure we're in the right place
        echo "Current directory contents:"
        ls -la
        
        # Build the Docker image
        docker build -t $ECR_REPOSITORY:$IMAGE_TAG .
        docker tag $ECR_REPOSITORY:$IMAGE_TAG $ECR_REPOSITORY:latest
        
        # Push images
        docker push $ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REPOSITORY:latest
        
        echo "Successfully built and pushed ${{ matrix.service }}"

  deploy-services:
    needs: [deploy-infrastructure, build-and-push]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get instance details
      id: get-instance
      run: |
        echo "instance_ip=${{ needs.deploy-infrastructure.outputs.instance_ip }}" >> $GITHUB_OUTPUT
        echo "unique_suffix=${{ needs.deploy-infrastructure.outputs.unique_suffix }}" >> $GITHUB_OUTPUT

    - name: Wait for EC2 instance to be ready
      run: |
        echo "Waiting for EC2 instance to be fully ready..."
        INSTANCE_IP="${{ steps.get-instance.outputs.instance_ip }}"
        
        # Wait for SSH to be available
        timeout=300
        while ! nc -z $INSTANCE_IP 22; do
          echo "Waiting for SSH on $INSTANCE_IP..."
          sleep 10
          timeout=$((timeout-10))
          if [ $timeout -le 0 ]; then
            echo "SSH timeout reached"
            break
          fi
        done
        
        echo "SSH is available on $INSTANCE_IP"
        sleep 30  # Additional buffer time

    - name: Deploy services to EC2
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ steps.get-instance.outputs.instance_ip }}
        username: ubuntu
        key: ${{ secrets.EC2_SSH_KEY }}
        timeout: 25m
        command_timeout: 25m
        script: |
          set -e  # Exit on any error
          
          echo "=== Starting EC2 Service Deployment ==="
          
          # Wait for any existing package operations to complete
          echo "Waiting for package manager to be available..."
          timeout=600  # 10 minutes
          while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 || sudo fuser /var/lib/apt/lists/lock >/dev/null 2>&1; do
            echo "Package manager is busy, waiting..."
            sleep 10
            timeout=$((timeout-10))
            if [ $timeout -le 0 ]; then
              echo "Package manager timeout - trying to force unlock..."
              sudo killall apt-get || true
              sudo rm -f /var/lib/apt/lists/lock || true
              sudo rm -f /var/lib/dpkg/lock-frontend || true
              sudo rm -f /var/lib/dpkg/lock || true
              sudo dpkg --configure -a || true
              break
            fi
          done
          
          # Wait for cloud-init to complete (with timeout)
          echo "Waiting for cloud-init to complete..."
          timeout 300 sudo cloud-init status --wait || echo "Cloud-init timeout - continuing..."
          
          # Wait for user_data script to complete
          echo "Waiting for initial setup to complete..."
          timeout=300
          while [ ! -f /home/ubuntu/setup-info.txt ] && [ $timeout -gt 0 ]; do
            echo "Waiting for EC2 initialization to complete..."
            sleep 10
            timeout=$((timeout-10))
          done
          
          # Check if Docker is already installed and working
          if sudo docker info > /dev/null 2>&1; then
            echo "âœ“ Docker is already installed and running"
          else
            echo "Installing Docker..."
            
            # Update package lists (with retries)
            for i in {1..3}; do
              if sudo apt-get update; then
                break
              else
                echo "apt-get update failed, retrying..."
                sleep 30
              fi
            done
            
            # Install Docker
            curl -fsSL https://get.docker.com -o get-docker.sh
            sudo sh get-docker.sh
            sudo usermod -aG docker ubuntu
            sudo systemctl start docker
            sudo systemctl enable docker
            
            # Install Docker Compose
            sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            sudo chmod +x /usr/local/bin/docker-compose
            
            echo "âœ“ Docker installation completed"
          fi
          
          # Ensure Docker is running
          sudo systemctl start docker || true
          
          # Wait for Docker to be ready
          echo "Waiting for Docker to be ready..."
          timeout 120 bash -c 'while ! sudo docker info > /dev/null 2>&1; do echo "Waiting for Docker..."; sleep 5; done' || {
            echo "Docker timeout - attempting restart..."
            sudo systemctl restart docker
            sleep 15
          }
          
          if sudo docker info > /dev/null 2>&1; then
            echo "âœ“ Docker is ready!"
          else
            echo "âŒ Docker failed to start properly"
            sudo systemctl status docker
            exit 1
          fi
          
          # Install AWS CLI if not present
          if ! command -v aws &> /dev/null; then
            echo "Installing AWS CLI..."
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            sudo apt-get install -y unzip || true
            unzip awscliv2.zip
            sudo ./aws/install
          fi
          
          # Configure AWS CLI
          aws configure set default.region ap-southeast-1
          
          # Login to ECR
          echo "Logging into ECR..."
          aws ecr get-login-password --region ap-southeast-1 | sudo docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.ap-southeast-1.amazonaws.com
          
          # Create monitoring directories
          echo "Setting up monitoring directories..."
          mkdir -p /home/ubuntu/monitoring/prometheus
          mkdir -p /home/ubuntu/monitoring/grafana/provisioning/datasources
          mkdir -p /home/ubuntu/monitoring/grafana/provisioning/dashboards
          mkdir -p /home/ubuntu/monitoring/grafana/dashboards
          
          # Create Prometheus config
          cat > /home/ubuntu/monitoring/prometheus/prometheus.yml << 'PROMETHEUS_EOF'
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          
          alerting:
            alertmanagers:
              - static_configs:
                  - targets: []
          
          rule_files:
            - "alerts.yml"
          
          scrape_configs:
            - job_name: 'prometheus'
              static_configs:
                - targets: ['localhost:9090']
          
            - job_name: 'ml-inference'
              static_configs:
                - targets: ['ml-inference:8001']
              metrics_path: '/metrics'
              scrape_interval: 10s
          
            - job_name: 'data-ingestion'
              static_configs:
                - targets: ['data-ingestion:8002']
              metrics_path: '/metrics'
              scrape_interval: 10s
          PROMETHEUS_EOF
          
          # Create alerts configuration
          cat > /home/ubuntu/monitoring/prometheus/alerts.yml << 'ALERTS_EOF'
          groups:
            - name: mlops_alerts
              interval: 30s
              rules:
                - alert: ServiceDown
                  expr: up == 0
                  for: 1m
                  labels:
                    severity: critical
                  annotations:
                    summary: "Service {{ \$labels.job }} is down"
                    description: "{{ \$labels.job }} has been down for more than 1 minute"
                
                - alert: HighResponseTime
                  expr: histogram_quantile(0.95, rate(data_ingestion_duration_seconds_bucket[5m])) > 1
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "High response time on {{ \$labels.job }}"
                    description: "95th percentile response time is {{ \$value }} seconds"
          ALERTS_EOF
          
          # Create Grafana datasource config
          cat > /home/ubuntu/monitoring/grafana/provisioning/datasources/prometheus.yml << 'DATASOURCE_EOF'
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://prometheus:9090
              isDefault: true
              editable: false
              jsonData:
                timeInterval: "15s"
                queryTimeout: "60s"
                httpMethod: "POST"
          DATASOURCE_EOF
          
          # Create Grafana dashboard provisioning config
          cat > /home/ubuntu/monitoring/grafana/provisioning/dashboards/dashboard.yml << 'DASHBOARD_EOF'
          apiVersion: 1
          providers:
            - name: 'MLOps Dashboards'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              updateIntervalSeconds: 10
              allowUiUpdates: true
              options:
                path: /var/lib/grafana/dashboards
                foldersFromFilesStructure: true
          DASHBOARD_EOF
          
          # Get ECR repository URLs
          UNIQUE_SUFFIX="${{ steps.get-instance.outputs.unique_suffix }}"
          echo "Using unique suffix: $UNIQUE_SUFFIX"
          
          ML_INFERENCE_REPO=$(aws ecr describe-repositories --repository-names "mlops/ml-inference-$UNIQUE_SUFFIX" --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
          DATA_INGESTION_REPO=$(aws ecr describe-repositories --repository-names "mlops/data-ingestion-$UNIQUE_SUFFIX" --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
          
          if [ -z "$ML_INFERENCE_REPO" ] || [ -z "$DATA_INGESTION_REPO" ]; then
            echo "âŒ Error: Could not retrieve ECR repository URLs"
            echo "Available repositories:"
            aws ecr describe-repositories --query 'repositories[].repositoryName' --output text
            exit 1
          fi
          
          echo "âœ“ Repository URLs retrieved:"
          echo "  ML Inference: $ML_INFERENCE_REPO"
          echo "  Data Ingestion: $DATA_INGESTION_REPO"
          
          # Create docker-compose.yml
          cat > /home/ubuntu/docker-compose.yml << COMPOSE_EOF
          version: '3.8'
          services:
            ml-inference:
              image: ${ML_INFERENCE_REPO}:latest
              ports:
                - "8001:8001"
              restart: always
              networks:
                - mlops-network
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
                
            data-ingestion:
              image: ${DATA_INGESTION_REPO}:latest
              ports:
                - "8002:8002"
              restart: always
              networks:
                - mlops-network
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
                
            prometheus:
              image: prom/prometheus:latest
              ports:
                - "9090:9090"
              volumes:
                - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
                - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml
                - prometheus-data:/prometheus
              command:
                - '--config.file=/etc/prometheus/prometheus.yml'
                - '--storage.tsdb.path=/prometheus'
                - '--web.console.libraries=/etc/prometheus/console_libraries'
                - '--web.console.templates=/etc/prometheus/consoles'
                - '--storage.tsdb.retention.time=200h'
                - '--web.enable-lifecycle'
                - '--web.enable-admin-api'
              restart: always
              networks:
                - mlops-network
                
            grafana:
              image: grafana/grafana:latest
              ports:
                - "3000:3000"
              environment:
                - GF_SECURITY_ADMIN_PASSWORD=admin
                - GF_USERS_ALLOW_SIGN_UP=false
                - GF_INSTALL_PLUGINS=
              volumes:
                - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
                - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
                - grafana-data:/var/lib/grafana
              depends_on:
                - prometheus
              restart: always
              networks:
                - mlops-network
                
          networks:
            mlops-network:
              driver: bridge
              
          volumes:
            prometheus-data:
            grafana-data:
          COMPOSE_EOF
          
          # Add user to docker group
          sudo usermod -aG docker ubuntu
          
          # Pull latest images
          echo "ğŸ“¥ Pulling latest images..."
          sudo docker pull ${ML_INFERENCE_REPO}:latest || exit 1
          sudo docker pull ${DATA_INGESTION_REPO}:latest || exit 1
          
          # Deploy services
          echo "ğŸš€ Deploying services..."
          cd /home/ubuntu
          sudo docker-compose down || true
          sudo docker-compose up -d
          
          # Wait for services to start
          echo "â³ Waiting for services to start..."
          sleep 90
          
          # Check service health with retries
          echo "ğŸ” Checking service health..."
          success=false
          for i in {1..12}; do
            echo "Health check attempt $i/12..."
            
            ML_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8001/health 2>/dev/null || echo "000")
            DATA_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8002/health 2>/dev/null || echo "000")
            PROM_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:9090/-/healthy 2>/dev/null || echo "000")
            GRAF_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:3000/api/health 2>/dev/null || echo "000")
            
            echo "  ML Inference: $ML_HEALTH"
            echo "  Data Ingestion: $DATA_HEALTH"
            echo "  Prometheus: $PROM_HEALTH" 
            echo "  Grafana: $GRAF_HEALTH"
            
            if [ "$ML_HEALTH" = "200" ] && [ "$DATA_HEALTH" = "200" ]; then
              echo "âœ… Core services are healthy!"
              success=true
              break
            else
              echo "â³ Services not ready yet, waiting..."
              sleep 25
            fi
          done
          
          if [ "$success" = true ]; then
            echo ""
            echo "ğŸ‰ Deployment completed successfully!"
            echo ""
            PUBLIC_IP=$(curl -s ifconfig.me)
            echo "ğŸ“Š Access URLs:"
            echo "  ğŸ¤– ML Inference:   http://${PUBLIC_IP}:8001"
            echo "  ğŸ“ˆ Data Ingestion: http://${PUBLIC_IP}:8002"
            echo "  ğŸ“Š Prometheus:     http://${PUBLIC_IP}:9090"
            echo "  ğŸ“ˆ Grafana:        http://${PUBLIC_IP}:3000 (admin/admin)"
            echo ""
            echo "âœ… All systems operational!"
          else
            echo "âŒ Service health check failed"
            echo "ğŸ“‹ Container status:"
            sudo docker-compose ps
            echo "ğŸ“‹ Container logs:"
            sudo docker-compose logs --tail=20
            exit 1
          fi